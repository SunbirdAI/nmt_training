{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b486eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating every 20 training steps.\n"
     ]
    }
   ],
   "source": [
    "import datasets \n",
    "\n",
    "from nmt_clean.config import config\n",
    "from nmt_clean.config_m2m_mul_en import config as data_config\n",
    "\n",
    "from nmt_clean.read_files import dataset_from_folders_m2m\n",
    "from nmt_clean.preprocess import Many2ManyProcessor\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5044656",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(config[\"model_checkpoint\"])\n",
    "main_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(config['model_checkpoint'])\n",
    "data_collator = transformers.DataCollatorForSeq2Seq(tokenizer, model = main_model) \n",
    "\n",
    "preprocess = Many2ManyProcessor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f9c27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|████████████████████████████                                                                                                                                            | 1/6 [00:02<00:12,  2.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████████████████████████████████████████████████                                                                                                                | 2/6 [00:08<00:18,  4.57s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████                                                                                    | 3/6 [00:10<00:10,  3.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 4/6 [00:15<00:08,  4.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 5/6 [00:18<00:03,  3.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:20<00:00,  3.39s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511ec8f3ced94625b99ccc87c896faa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/3684 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8e7389454248a99607116b911affb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3684 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.pyenv/versions/pytorch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty string\n",
      "empty string\n",
      "empty string\n",
      "empty string\n",
      "empty string\n"
     ]
    }
   ],
   "source": [
    "paired_datasets = preprocess.dataset_from_folders_m2m(data_config[\"training_subset_paths\"])\n",
    "\n",
    "paired_datasets = datasets.concatenate_datasets(paired_datasets)\n",
    "paired_datasets = paired_datasets.shuffle(seed=42)\n",
    "paired_datasets = paired_datasets.flatten_indices()  # rewrite the shuffled dataset on disk as contiguous chunks of data\n",
    "\n",
    "preprocessing_function = preprocess.attach_tokenizer(tokenizer)\n",
    "\n",
    "training_dataset = paired_datasets.map(preprocessing_function, remove_columns=[\"translation\"], batched=True)\n",
    "\n",
    "#training_tokens = preprocess.iterative_preprocess(paired_datasets,tokenizer )\n",
    "\n",
    "\n",
    "#tokens = preprocess.iterative_preprocess(paired_datasets,tokenizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a71e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_paired_datasets = preprocess.dataset_from_folders_m2m(data_config[\"validation_subset_paths\"])\n",
    "\n",
    "val_paired_datasets = datasets.concatenate_datasets(val_paired_datasets)\n",
    "#val_paired_datasets = paired_datasets.shuffle(seed=42)\n",
    "#val_paired_datasets = paired_datasets.flatten_indices()  # rewrite the shuffled dataset on disk as contiguous chunks of data\n",
    "\n",
    "preprocessing_function = preprocess.attach_tokenizer(tokenizer)\n",
    "\n",
    "valid_dataset = val_paired_datasets.map(preprocessing_function, remove_columns=[\"translation\"], batched=True)\n",
    "\n",
    "#training_tokens = preprocess.iterative_preprocess(paired_datasets,tokenizer )\n",
    "\n",
    "\n",
    "#tokens = preprocess.iterative_preprocess(paired_datasets,tokenizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dict =  {\n",
    "            \"ach\":{\n",
    "                \"all\":[config['data_dir'] + \"v7.0/supervised/mul-en/test_ach.src\"],\n",
    "                \"en\":[],\n",
    "                \"lgg\":[],\n",
    "                \"lug\":[],\n",
    "                \"nyn\":[],\n",
    "                \"teo\":[]\n",
    "            },\n",
    "            \"en\": {\n",
    "                \"all\":[config['data_dir'] + \"v7.0/supervised/mul-en/test_ach.tgt\"], #all tgts here are the same file \n",
    "                \"ach\":[],\n",
    "                \"lgg\":[],\n",
    "                \"lug\":[],\n",
    "                \"nyn\":[],\n",
    "                \"teo\":[]\n",
    "            },\n",
    "            \"lgg\":{\n",
    "                \"all\":[config['data_dir'] + \"v7.0/supervised/mul-en/test_lgg.src\"],\n",
    "                \"en\":[],\n",
    "                \"ach\":[],\n",
    "                \"lug\":[],\n",
    "                \"nyn\":[],\n",
    "                \"teo\":[]\n",
    "            },\n",
    "            \"lug\":{\n",
    "                \"all\":[config['data_dir'] + \"v7.0/supervised/mul-en/test_lug.src\"],\n",
    "                \"en\":[],\n",
    "                \"lgg\":[],\n",
    "                \"ach\":[],\n",
    "                \"nyn\":[],\n",
    "                \"teo\":[]\n",
    "            },\n",
    "            \"nyn\":{\n",
    "                \"all\":[config['data_dir'] + \"v7.0/supervised/mul-en/test_nyn.src\"],\n",
    "                \"en\":[],\n",
    "                \"lgg\":[],\n",
    "                \"lug\":[],\n",
    "                \"ach\":[],\n",
    "                \"teo\":[]\n",
    "            },\n",
    "            \"teo\":{\n",
    "                \"all\":[config['data_dir'] + \"v7.0/supervised/mul-en/test_teo.src\"],\n",
    "                \"en\":[],\n",
    "                \"lgg\":[],\n",
    "                \"lug\":[],\n",
    "                \"nyn\":[],\n",
    "                \"ach\":[]\n",
    "            }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80171bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('salt-translation-plus-external-datasets'):\n",
    "    !wget https://sunbird-translate.s3.us-east-2.amazonaws.com/salt-translation-plus-external-datasets.zip\n",
    "    !unzip salt-translation-plus-external-datasets.zip\n",
    "    display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ddedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://sunbird-translate.s3.us-east-2.amazonaws.com/salt-translation-plus-external-datasets.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d106455",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip salt-translation-plus-external-datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dcd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/ali/Documents/repos/NMT_clean/salt-translation-plus-external-datasets/backtranslated-from-eng.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file.readlines())\n",
    "\n",
    "for json_str_idx in range(len(json_list)):\n",
    "    json_list[json_str_idx] = json.loads(json_list[json_str_idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d89fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the strongest typhoons on record likely killed hundreds of people as tsunami-like waves and savage winds flattened entire communities in the Philippines, authorities said Saturday.\n",
      "Our panel today will slice and dice the topic, offering you practical insights and actions to reposition yourself in order to stay competitive.\n",
      "He is used to giving out large bags of money can't he finance his own oil ?\n",
      "why didn't the government use the money to demarcate Uganda South Sudan, Uganda DRC, Uganda Rwanda etc?\n",
      "Beyiya just coz bali mu outside countries (uganda) that aside I have no doubt that uganda can't and didn't take any measure to first prove their documents of being doctors.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,50000,10000):\n",
    "    print(json_list[i][\"text\"][\"eng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2744e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 uganda top 100 mid size companies survey.\n"
     ]
    }
   ],
   "source": [
    "print(json_list[-1][\"text\"][\"eng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20f3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

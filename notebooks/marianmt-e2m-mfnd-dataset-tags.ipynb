{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython import display\n!pip install transformers\n!pip install sacrebleu\n!pip install sacremoses\n!pip install datasets\n!pip install wandb\n!pip install sentencepiece\n!pip install numpy requests nlpaug\n!wget https://raw.githubusercontent.com/SunbirdAI/nmt_training/main/salt_v2/salt.py\n!wget https://raw.githubusercontent.com/SunbirdAI/nmt_training/main/nmt_clean/augmentations.py\ndisplay.clear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-22T17:43:02.001610Z","iopub.execute_input":"2023-03-22T17:43:02.002069Z","iopub.status.idle":"2023-03-22T17:44:29.814523Z","shell.execute_reply.started":"2023-03-22T17:43:02.002025Z","shell.execute_reply":"2023-03-22T17:44:29.812593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from augmentations import Augmentations\nimport datasets\nfrom IPython import display\nimport nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport sentencepiece\nimport sacrebleu\nimport sacremoses\nimport salt\nimport tqdm\nimport transformers\nimport torch\nimport wandb\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:18.877399Z","iopub.execute_input":"2023-03-22T18:17:18.877845Z","iopub.status.idle":"2023-03-22T18:17:18.885151Z","shell.execute_reply.started":"2023-03-22T18:17:18.877806Z","shell.execute_reply":"2023-03-22T18:17:18.883670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:19.143391Z","iopub.execute_input":"2023-03-22T18:17:19.143830Z","iopub.status.idle":"2023-03-22T18:17:19.150807Z","shell.execute_reply.started":"2023-03-22T18:17:19.143791Z","shell.execute_reply":"2023-03-22T18:17:19.149815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters for mul-en models\nconfig = {\n    'source_language': 'eng',\n    'target_language': 'many',\n    'metric_for_best_model': 'loss',\n    'effective_train_batch_size': 5000,\n    'max_input_length': 128,\n    'validation_samples_per_language': 500,\n    'eval_languages': [\"ach\", \"lgg\", \"lug\", \"nyn\", \"teo\", \"luo\"],\n    'eval_pretrained_model': True,\n    'learning_rate': 5e-4,\n    'num_train_epochs': 10,\n    'label_smoothing_factor': 0.1,\n    'mt560_relative_sample_rate' : 0.2,\n    'flores200_training_data': True,\n    'mt560_training_data': True,\n    'monolingual_training_data': False,\n    'back_translation_training_data': True,\n    'google_back_translation_data': True,\n    'named_entities_training_data': False,\n    'lafand_training_data': True,\n    'tag_subsets': True,\n    'early_stopping_patience': 4,\n    'eval_steps_interval': 50,\n    'data_dir': 'salt-translation-plus-external-datasets-15-3-23',\n}\n\nconfig['language_pair'] = (f'{config[\"source_language\"]}-'\n                           f'{config[\"target_language\"]}')\nconfig['wandb_project'] = f'sunbird-translate-{config[\"language_pair\"]}'\nconfig['model_checkpoint'] = f'Helsinki-NLP/opus-mt-en-mul'\n#config['model_checkpoint'] = f'/kaggle/input/nmt-marianmt-w-mafand/best/checkpoint-600'\n#config['model_checkpoint'] = (\n#    '/content/gdrive/MyDrive/Translation/saved_models/'\n#    'marianmt-many-eng/checkpoint-1400')\n\n\n# Find the biggest batch size that fits in GPU memory\nAPPROX_MODEL_MEMORY_SIZE_MB = 310\nif torch.cuda.is_available():\n  gpu_info = !nvidia-smi\n  gpu_memory_mb = int(gpu_info[9].split()[10][:-3])\n  per_device_max_batch_size = int(gpu_memory_mb / APPROX_MODEL_MEMORY_SIZE_MB)\n  B = config['effective_train_batch_size'] \n  factors = np.array([x for x in range(1, B) if B % x == 0])\n  config['train_batch_size'] = int(max(\n      factors[factors < per_device_max_batch_size]))\n  config['eval_batch_size'] = config['train_batch_size']\nelse:\n  config['train_batch_size'] = 1\n  config['eval_batch_size'] = 1\nconfig['gradient_accumulation_steps'] = int(\n    config['effective_train_batch_size'] / config['train_batch_size'])\n\n# Trainer settings\nconfig['train_settings'] = transformers.Seq2SeqTrainingArguments(\n    output_dir= f'/kaggle/working/best',\n    evaluation_strategy = 'steps',\n    eval_steps = config['eval_steps_interval'],\n    save_steps = config['eval_steps_interval'],\n    gradient_accumulation_steps = config['gradient_accumulation_steps'],\n    learning_rate = config['learning_rate'],\n    per_device_train_batch_size = config['train_batch_size'],\n    per_device_eval_batch_size = config['eval_batch_size'],\n    weight_decay = 0.01,\n    save_total_limit = 3,\n    num_train_epochs = config['num_train_epochs'],\n    predict_with_generate = True,\n    fp16 = torch.cuda.is_available(),\n    logging_dir = f'/kaggle/working/best',\n    report_to = 'wandb',\n    run_name = f'{config[\"source_language\"]}-{config[\"target_language\"]}',\n    load_best_model_at_end=True,\n    metric_for_best_model = config['metric_for_best_model'],\n    label_smoothing_factor = config['label_smoothing_factor']\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:19.345687Z","iopub.execute_input":"2023-03-22T18:17:19.346140Z","iopub.status.idle":"2023-03-22T18:17:19.368345Z","shell.execute_reply.started":"2023-03-22T18:17:19.346101Z","shell.execute_reply":"2023-03-22T18:17:19.367376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config['training_subset_ids'] = ['salt-train', 'ai4d']\n\nif config['lafand_training_data']:\n    config['training_subset_ids'].extend(['lafand-en-lug-combined', 'lafand-en-luo-combined'])\n\nif config['flores200_training_data']:\n    config['training_subset_ids'] .append('flores200')\n\nif config['back_translation_training_data']:\n    config['training_subset_ids'].extend( ['bt_ach_en_14_3_23', 'bt_lug_en_14_3_23'])\n\nif config['back_translation_training_data']:\n    config['training_subset_ids'].extend(['backtranslated-from-eng-google', 'backtranslated-from-lug-google' ])\n\nconfig['training_subset_ids'] = config['training_subset_ids']*5\n\nif config['mt560_training_data']:\n    config['training_subset_ids'].extend([\n        'mt560_ach', 'mt560_lug', 'mt560_nyn','mt560_luo'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:19.533562Z","iopub.execute_input":"2023-03-22T18:17:19.533976Z","iopub.status.idle":"2023-03-22T18:17:19.542030Z","shell.execute_reply.started":"2023-03-22T18:17:19.533937Z","shell.execute_reply":"2023-03-22T18:17:19.540881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config[\"tag_subsets\"]:\n    config['training_subset_tags'] = [\"hq\", \"hq\"]\n\n    if config['lafand_training_data']:\n        config['training_subset_tags'].extend([ \"hq\",\"hq\" ])\n\n    if config['flores200_training_data']:\n        config['training_subset_tags'] .append(\"hq\") #hq?\n\n    if config['back_translation_training_data']:\n        config['training_subset_tags'].extend( [ \"bt\", \"bt\" ])\n\n    if config['back_translation_training_data']:\n        config['training_subset_tags'].extend([ \"ggl\", \"ggl\" ])\n\n    config['training_subset_tags'] = config['training_subset_tags']*5\n\n    if config['mt560_training_data']:\n        config['training_subset_tags'].extend([\n            \"ood\", \"ood\", \"ood\", \"ood\" ])\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:19.754428Z","iopub.execute_input":"2023-03-22T18:17:19.754859Z","iopub.status.idle":"2023-03-22T18:17:19.763000Z","shell.execute_reply.started":"2023-03-22T18:17:19.754824Z","shell.execute_reply":"2023-03-22T18:17:19.761689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(config[\"training_subset_tags\"]) == len(config[\"training_subset_ids\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:19.948295Z","iopub.execute_input":"2023-03-22T18:17:19.949395Z","iopub.status.idle":"2023-03-22T18:17:19.954402Z","shell.execute_reply.started":"2023-03-22T18:17:19.949348Z","shell.execute_reply":"2023-03-22T18:17:19.953053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('salt-translation-plus-external-datasets-15-3-23'):\n    !wget https://sunbird-translate.s3.us-east-2.amazonaws.com/salt-translation-plus-external-datasets-15-3-23.zip\n    !unzip salt-translation-plus-external-datasets-15-3-23.zip\n    display.clear_output()","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:20.208964Z","iopub.execute_input":"2023-03-22T18:17:20.209408Z","iopub.status.idle":"2023-03-22T18:17:20.217666Z","shell.execute_reply.started":"2023-03-22T18:17:20.209369Z","shell.execute_reply":"2023-03-22T18:17:20.216435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n# training_subsets = [\n#     salt.translation_dataset(\n#         path=f'{config[\"data_dir\"]}/{id}.jsonl',\n#         source_language=config['source_language'],\n#         target_language=config['target_language'],\n#         allow_target_language_in_source=False,\n#         prefix_target_language_in_source=True,\n#         dataset_prefixes = dataset_tags,\n#         languages_to_include=config['eval_languages'],\n#         keep_unaugmented_src = False)\n#     for id, dataset_tags in tqdm(zip(config['training_subset_ids'],config['training_subset_tags'] ) )\n# ]\n\ntraining_subsets = []\n\nfor id, dataset_tags in tqdm(zip(config['training_subset_ids'],config['training_subset_tags'] )):\n    for language in config[\"eval_languages\"]:\n        training_subset = salt.translation_dataset(\n            path=f'{config[\"data_dir\"]}/{id}.jsonl',\n            source_language=config['source_language'],\n            target_language=language,\n            allow_target_language_in_source=False,\n            prefix_target_language_in_source=False,\n            dataset_prefixes = [f\">>{language}_{dataset_tags}<<\"],\n            languages_to_include=language,\n            keep_unaugmented_src = False)\n        training_subsets.append(training_subset)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:20.466960Z","iopub.execute_input":"2023-03-22T18:17:20.467365Z","iopub.status.idle":"2023-03-22T18:17:51.966017Z","shell.execute_reply.started":"2023-03-22T18:17:20.467330Z","shell.execute_reply":"2023-03-22T18:17:51.963743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_probabilities = np.array([len(s) for s in training_subsets])\n# sample_probabilities = sample_probabilities * np.array(\n#     [config['mt560_relative_sample_rate'] if ('mt560' in id) or ('google' in id)  else 1.0\n#      for id in config['training_subset_ids']])\n# sample_probabilities = sample_probabilities / np.sum(sample_probabilities)\n\n# train_data_raw = datasets.interleave_datasets(\n#     training_subsets, sample_probabilities)\ntrain_data_raw = datasets.concatenate_datasets(training_subsets)\ntrain_data_raw = train_data_raw.shuffle()\ntrain_data_raw = train_data_raw.flatten_indices()","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:51.967397Z","iopub.status.idle":"2023-03-22T18:17:51.968037Z","shell.execute_reply.started":"2023-03-22T18:17:51.967713Z","shell.execute_reply":"2023-03-22T18:17:51.967747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_raw[1919379]","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:51.970409Z","iopub.status.idle":"2023-03-22T18:17:51.971015Z","shell.execute_reply.started":"2023-03-22T18:17:51.970709Z","shell.execute_reply":"2023-03-22T18:17:51.970739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_subsets = [\n    salt.translation_dataset(\n        path=f'{config[\"data_dir\"]}/salt-dev.jsonl',\n        source_language=\"eng\",\n        target_language=language,\n        keep_unaugmented_src = False,\n        allow_target_language_in_source=False,\n        prefix_target_language_in_source=False,\n        dataset_prefixes = [f\">>{language}_hq<<\"]\n    )\n    for language in config['eval_languages'][:-1]\n]\nvalidation_data_raw = datasets.concatenate_datasets(validation_subsets)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:51.972675Z","iopub.status.idle":"2023-03-22T18:17:51.973235Z","shell.execute_reply.started":"2023-03-22T18:17:51.972943Z","shell.execute_reply":"2023-03-22T18:17:51.972973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentence_format(input):\n    '''Ensure capital letter at the start and full stop at the end.'''\n    try:\n        input = input[0].capitalize() + input[1:]\n        if input[-1] not in ['.', '!', '?']:\n            input = input + '.'\n    except:\n        return \"\"\n    return input\n\ndef preprocess(examples):\n    normalizer = sacremoses.MosesPunctNormalizer()  \n    inputs = []\n    targets = []\n    for input, target in zip(examples['source'], examples['target']):\n        if not len(input):\n          input = target\n        inputs.append(sentence_format(normalizer.normalize(input)))\n        targets.append(sentence_format(normalizer.normalize(target)))\n    \n    model_inputs = tokenizer(\n        inputs, text_target=targets,\n        max_length=config['max_input_length'], truncation=True)\n\n    return model_inputs\n\ndef postprocess(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds, eval_languages, samples_per_language):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n        \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess(decoded_preds, decoded_labels)\n    result = {}\n    for i, lang in enumerate(eval_languages):\n        \n        result_subset = metric.compute(\n            predictions=decoded_preds[\n                i*samples_per_language:(i+1)*samples_per_language],\n            references=decoded_labels[\n                i*samples_per_language:(i+1)*samples_per_language])\n        result[f\"BLEU_{lang}\"] = result_subset[\"score\"]\n        \n    result[\"BLEU_mean\"] = np.mean(\n        [result[f\"BLEU_{lang}\"] for lang in eval_languages])\n    \n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:51.975220Z","iopub.status.idle":"2023-03-22T18:17:51.976046Z","shell.execute_reply.started":"2023-03-22T18:17:51.975818Z","shell.execute_reply":"2023-03-22T18:17:51.975845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = transformers.AutoModelForSeq2SeqLM.from_pretrained(config['model_checkpoint'])\ntokenizer = transformers.AutoTokenizer.from_pretrained(config['model_checkpoint'])\ndata_collator = transformers.DataCollatorForSeq2Seq(tokenizer, model = model) \nmetric = datasets.load_metric('sacrebleu')","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:51.977149Z","iopub.status.idle":"2023-03-22T18:17:51.977572Z","shell.execute_reply.started":"2023-03-22T18:17:51.977356Z","shell.execute_reply":"2023-03-22T18:17:51.977376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config['target_language'] == 'many':\n    replacements = {'nyn_ood': 'kin',\n                    'nyn_ggl': 'lin',\n                    'nyn_hq': 'tso',\n                    'nyn_bt': 'nya',\n                    'teo_ood': 'som',\n                    'teo_ggl': 'ara',\n                    'teo_hq': 'ceb', \n                    'teo_bt': 'oss',\n                    'lgg_ood': 'run',\n                    'lgg_ggl': 'mfe',\n                    'lgg_bt': 'ilo',\n                    'lgg_hq': 'pes',\n                    'ach_ood': 'smo',\n                    'ach_ggl': 'hil',\n                    'ach_hq': 'niu',\n                    'ach_bt': 'sag',\n                    'lug_ood': 'fij',\n                    'lug_ggl': 'war',\n                    'lug_hq': 'umb',\n                    'lug_bt': 'gil'\n                    }\n#['>>ewe<<','>>sna<<','>>lin<<','>>toi_Latn<<','>>ceb<<','>>oss<<','>>run<<','>>mfe<<','>>ilo<<','>>zlm_Latn<<','>>pes<<',\n#'>>smo<<','>>hil<<','>>niu<<','>>sag<<','>>fij<<','>>cmn_Hans<<','>>nya<<','>>tso<<','>>war<<',\n#'>>gil<<','>>hau_Latn<<','>>umb<<','>>glv<<','>>tvl<<','>>ton<<','>>zul<<','>>kal<<','>>pag<<','>>cmn_Hant<<','>>pus<<','>>abk<<','>>pap<<','>>hat<<','>>mkd<<','>>tuk_Latn<<','>>yor<<','>>tuk<<','>>sqi<<','>>tir<<','>>mlg<<','>>tur<<','>>ido_Latn<<','>>mai<<','>>ibo<<','>>srp_Cyrl<<','>>srp_Latn<<','>>kir_Cyrl<<','>>heb<<','>>bos_Latn<<','>>bak<<','>>ast<<','>>som<<','>>tah<<','>>chv<<','>>kek_Latn<<','>>lug<<','>>vie<<','>>wln<<','>>isl<<','>>hye<<','>>mah<<','>>yue_Hant<<','>>crh_Latn<<','>>amh<<','>>nds<<','>>pan_Guru<<','>>xho<<','>>ukr<<','>>cat<<','>>afr<<','>>tat<<','>>guj<<','>>jpn<<','>>mon<<','>>eus<<','>>nob<<','>>glg<<','>>ind<<','>>sin<<','>>cym<<','>>zho_Hant<<','>>zho_Hans<<','>>tgk_Cyrl<<','>>aze_Latn<<','>>ltz<<','>>bod<<','>>asm<<','>>tel<<','>>urd<<','>>kaz_Cyrl<<','>>lat_Latn<<','>>gla<<','>>kan<<','>>bul<<','>>kin<<','>>ina_Latn<<','>>ron<<','>>spa<<','>>csb_Latn<<','>>iba<<','>>tha<<','>>nno<<','>>hrv<<','>>fry<<','>>bre<<','>>mar<<','>>sme<<','>>swe<<','>>deu<<','>>jav<<','>>snd_Arab<<','>>ben<<','>>cmn<<','>>ces<<''>>ita<<','>>fin<<','>>por<<','>>hin<<','>>hun<<','>>mal<<','>>pol<<','>>fra<<','>>nld<<','>>epo<<','>>slv<<','>>hsb<<','>>kur_Latn<<','>>ori<<','>>tam<<','>>bel<<','>>dan<<','>>ara<<','>>mya<<','>>rus<<','>>mri<<','>>est<<','>>uzb_Latn<<','>>lao<<','>>yid<<','>>uzb_Cyrl<<','>>uig_Arab<<','>>lit<<','>>zho<<','>>lav<<','>>ell<<','>>kat<<''>>gle<<','>>mlt<<','>>khm<<','>>oci<<','>>kur_Arab<<','>>ang_Latn<<','>>kaz_Latn<<','>>wol<<','>>sun<<','>>chr<<','>>tat_Latn<<','>>mhr<<','>>tyv<<','>>rom<<','>>cha<<','>>kab<<','>>nav<<','>>arg<<','>>khm_Latn<<','>>bul_Latn<<','>>udm<<','>>quc<<','>>cor<<','>>san_Deva<<','>>fao<<','>>bel_Latn<<','>>jbo_Latn<<','>>yue<<','>>grn<<','>>sco<<','>>arq<<','>>ltg<<','>>yue_Hans<<','>>min<<''>>nan<<','>>bam_Latn<<','>>ido<<','>>ile_Latn<<','>>wuu<<','>>crh<<','>>tlh_Latn<<','>>lzh<<','>>jbo<<','>>lzh_Hans<<','>>vol_Latn<<','>>lfn_Latn<<','>>arz<<']\n    for r in replacements:\n        if (f'>>{r}<<' not in tokenizer.encoder and\n            f'>>{replacements[r]}<<' in tokenizer.encoder):\n            tokenizer.encoder[f\">>{r}<<\"] = tokenizer.encoder[f\">>{replacements[r]}<<\"]\n            del tokenizer.encoder[f\">>{replacements[r]}<<\"]\n\n    # Check that all the evaluation language codes are mapped to something.\n#     for r in config['eval_languages']:\n#         if f'>>{r}<<' not in tokenizer.encoder:\n#             raise ValueError(f'Language code {r} not found in the encoder.')","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:51.978973Z","iopub.status.idle":"2023-03-22T18:17:51.979391Z","shell.execute_reply.started":"2023-03-22T18:17:51.979170Z","shell.execute_reply":"2023-03-22T18:17:51.979190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data  = train_data_raw.map(\n    preprocess,\n    remove_columns=['source', 'target', 'source_language', 'target_language'],\n    batched=True)\n\nvalidation_data  = validation_data_raw.map(\n    preprocess,\n    remove_columns=['source', 'target', 'source_language', 'target_language'],\n    batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:51.980511Z","iopub.status.idle":"2023-03-22T18:17:51.980913Z","shell.execute_reply.started":"2023-03-22T18:17:51.980705Z","shell.execute_reply":"2023-03-22T18:17:51.980725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\nimport os\nos.environ[\"WANDB_API_KEY\"] = secret_value_0\nwandb.init(project=config['wandb_project'], config=config, entity=\"azawahry\")\n\ntransformers.logging.set_verbosity_error()\n\ntrainer = transformers.Seq2SeqTrainer(\n    model,\n    config['train_settings'],\n    train_dataset = train_data,\n    eval_dataset = validation_data,\n    data_collator = data_collator,\n    tokenizer = tokenizer,\n    compute_metrics = lambda x: compute_metrics(\n        x, config['eval_languages'][:-1], config['validation_samples_per_language']),\n    callbacks = [\n        transformers.EarlyStoppingCallback(\n            early_stopping_patience = config['early_stopping_patience'])],\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T11:52:01.033779Z","iopub.execute_input":"2023-03-17T11:52:01.034275Z","iopub.status.idle":"2023-03-17T11:52:38.190474Z","shell.execute_reply.started":"2023-03-17T11:52:01.034227Z","shell.execute_reply":"2023-03-17T11:52:38.189453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if config['eval_pretrained_model']:\n#     trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T11:52:38.195292Z","iopub.execute_input":"2023-03-17T11:52:38.197742Z","iopub.status.idle":"2023-03-17T11:52:38.204177Z","shell.execute_reply.started":"2023-03-17T11:52:38.197700Z","shell.execute_reply":"2023-03-17T11:52:38.203008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T11:52:38.209112Z","iopub.execute_input":"2023-03-17T11:52:38.210546Z","iopub.status.idle":"2023-03-17T15:36:51.814471Z","shell.execute_reply.started":"2023-03-17T11:52:38.210508Z","shell.execute_reply":"2023-03-17T15:36:51.813396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
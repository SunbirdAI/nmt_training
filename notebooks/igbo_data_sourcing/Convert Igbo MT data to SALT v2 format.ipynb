{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84a843c-72dd-4fd1-9bc5-595fd2835b56",
   "metadata": {},
   "source": [
    "# Conversion of machine translation datasets to SALT v2 format\n",
    "\n",
    "This notebook converts existing Igbo machine translation datasets that are sourced, into the SALT v2 format.\n",
    "\n",
    "The new format is .jsonl and looks like this: \\\n",
    "`\n",
    "    [\n",
    "    {'text': {'ibo': 'Anas na-agwa anyị na ọ zaghachiri, sị, \"Ndị niile na-atụ egwu Allah.\"',\n",
    "  'eng': 'Anas tells us that he replied, \"All those who fear Allah.\"'}}\n",
    "  ]\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f53ebadc-8089-474a-9b74-2fd038cf0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import glob\n",
    "import requests\n",
    "import gzip\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45c667bb-19bc-4f89-9ce7-828f32d1ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "OUTPUT_DIR = 'salt-translation-plus-external-datasets/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "temp_dir = \"temp_dir/\"\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.mkdir(temp_dir) \n",
    "\n",
    "DATA_DIR = 'v7-dataset/v7.0/supervised/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1baad3b5-8de8-48cf-a1f8-4773b7edf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_list(path):\n",
    "    with open(path) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        return lines\n",
    "    \n",
    "def url_to_list(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03692a",
   "metadata": {},
   "source": [
    "## Test and Dev Data\n",
    "\n",
    "TODO: To use existing SALT dev and test data, but to translate them into Igbo. \n",
    "\n",
    "Pricing for Igbo Translation can be found [here](https://docs.google.com/document/d/1BwSw8CCm9q71iZ7vuMpeOckDFdPNhwoC6bJ-BZNE_bU/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DOWNLOAD SALT DATA\n",
    "# !wget https://sunbird-translate.s3.us-east-2.amazonaws.com/salt-translation-plus-external-datasets.zip\n",
    "# !unzip salt-translation-plus-external-datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e782f5c0-ca19-46db-bae9-04a8de256d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['lug', 'ach', 'nyn', 'luo']\n",
    "\n",
    "if not os.path.exists('v7-dataset'):\n",
    "    !wget https://sunbird-translate.s3.us-east-2.amazonaws.com/v7-dataset.zip\n",
    "    !unzip v7-dataset.zip\n",
    "    display.clear_output()\n",
    "    \n",
    "for language in languages:\n",
    "    source = file_to_list(DATA_DIR + f'mul-en/train_mt560_{language}.src')\n",
    "    target = file_to_list(DATA_DIR + f'mul-en/train_mt560_{language}.tgt')\n",
    "\n",
    "    sentences = []\n",
    "    for s, t in zip(source, target):\n",
    "        sentences.append({'text': {language: s, 'eng': t}})\n",
    "\n",
    "    with open(OUTPUT_DIR + f'mt560_{language}.jsonl', 'w') as outfile:\n",
    "        for entry in sentences:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2e6cf",
   "metadata": {},
   "source": [
    "# Parallel Igbo-English Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecc22f",
   "metadata": {},
   "source": [
    "### MT560 Data Source\n",
    "Follow the approach here to get any language available in mt560:\n",
    "https://colab.research.google.com/drive/1_a_d4phiWFhcLGkom3qIfelblxbSiTSB?usp=sharing\n",
    "\n",
    "The parallel Igbo data has `415234` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44671bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt560 = pd.read_csv(\"/Users/user/Downloads/mt560.csv.gz\", engine='c')\n",
    "mt560_igbo = mt560[mt560[\"source_language\"]==\"ibo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b589ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415234 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english</th>\n",
       "      <th>source_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jehova Chineke ga - enyekwa ya ocheeze nke Dev...</td>\n",
       "      <td>And Jehovah God will give him the throne of Da...</td>\n",
       "      <td>ibo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ka ihu anyanwụ malitere ịpụta, anyị hụrụ ntụpọ...</td>\n",
       "      <td>As the solar disk started to emerge, we saw th...</td>\n",
       "      <td>ibo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kpọghachite m, m ga - alọghachikwa, n'ihi na ị...</td>\n",
       "      <td>Cause me to turn back, and I shall readily tur...</td>\n",
       "      <td>ibo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ndị Ezi Omume Ga - enwu Gbaa Dị Ka Anyanwụ</td>\n",
       "      <td>The Righteous Ones Will Shine as Brightly as t...</td>\n",
       "      <td>ibo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ndị ji obi ụtọ na ịdị n'otu na - ejere Jehova ...</td>\n",
       "      <td>Happy and enjoying their united service to Jeh...</td>\n",
       "      <td>ibo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "3  Jehova Chineke ga - enyekwa ya ocheeze nke Dev...   \n",
       "4  Ka ihu anyanwụ malitere ịpụta, anyị hụrụ ntụpọ...   \n",
       "5  Kpọghachite m, m ga - alọghachikwa, n'ihi na ị...   \n",
       "7         Ndị Ezi Omume Ga - enwu Gbaa Dị Ka Anyanwụ   \n",
       "8  Ndị ji obi ụtọ na ịdị n'otu na - ejere Jehova ...   \n",
       "\n",
       "                                             english source_language  \n",
       "3  And Jehovah God will give him the throne of Da...             ibo  \n",
       "4  As the solar disk started to emerge, we saw th...             ibo  \n",
       "5  Cause me to turn back, and I shall readily tur...             ibo  \n",
       "7  The Righteous Ones Will Shine as Brightly as t...             ibo  \n",
       "8  Happy and enjoying their united service to Jeh...             ibo  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(mt560_igbo), \"\\n\")\n",
    "mt560_igbo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for row in mt560_igbo.itertuples():\n",
    "    sentences.append({'text': {'ibo': row.source, 'eng': row.english}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e63bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR + 'mt560_ibo.jsonl', 'w', encoding='UTF-8', errors='ignore') as outfile:\n",
    "    for entry in sentences:\n",
    "        json.dump(entry, outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## UNCOMMENT IF WE CHOOSE TO SPLIT THE DATA INSTEAD INTO TRAIN, DEV, TEST\n",
    "# train, dev = train_test_split(mt560_igbo, test_size=0.01, shuffle=True)\n",
    "# test = dev[:500]\n",
    "\n",
    "# print(len(train), len(dev), len(test))\n",
    "\n",
    "# train_sentences = []\n",
    "# dev_sentences = []\n",
    "# test_sentences = []\n",
    "\n",
    "# for row in train.itertuples():\n",
    "#     train_sentences.append({'text': {'ibo': row.source, 'eng': row.english}})\n",
    "\n",
    "# for row in dev.itertuples():\n",
    "#     dev_sentences.append({'text': {'ibo': row.source, 'eng': row.english}})\n",
    "\n",
    "# for row in test.itertuples():\n",
    "#     test_sentences.append({'text': {'ibo': row.source, 'eng': row.english}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768108e",
   "metadata": {},
   "source": [
    "### IgboNLP Data [Source](https://github.com/IgnatiusEzeani/IGBONLP/tree/master/ig_en_mt/benchmark_dataset)\n",
    "This data has `10792` samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11356c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "igbo_mt = [\"test.en\", \"test.ig\", \"train.en\", \"train.ig\", \"val.en\", \"val.ig\"]\n",
    "for data in igbo_mt:\n",
    "    !wget -P $temp_dir https://raw.githubusercontent.com/IgnatiusEzeani/IGBONLP/master/ig_en_mt/benchmark_dataset/$data\n",
    "    display.clear_output()\n",
    "\n",
    "## merge all .ig and .en files in igbo_mt list\n",
    "for lang in [\"en\", \"ig\"]:\n",
    "    with open(temp_dir+f'igbo_en.{lang}', 'w') as outfile: \n",
    "        for language_split in igbo_mt:\n",
    "            if language_split.endswith(lang):\n",
    "                with open(temp_dir+language_split) as infile:\n",
    "                    outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\")\n",
    "\n",
    "# load merged .ig and .en data and convert to the salt data format\n",
    "igbo = file_to_list(temp_dir+\"igbo_en.ig\")\n",
    "en = file_to_list(temp_dir+\"igbo_en.en\")\n",
    "\n",
    "sentences = []\n",
    "for s, t in zip(igbo, en):\n",
    "    sentences.append({'text': {'ibo': s, 'eng': t}})\n",
    "\n",
    "with open(OUTPUT_DIR + 'igbo_en.jsonl', 'w', encoding='utf-8') as outfile:\n",
    "    for entry in sentences:\n",
    "        json.dump(entry, outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "# delete temporary directory\n",
    "!rm -rf $temp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79afbb3",
   "metadata": {},
   "source": [
    "### Masakhane Eng-Igbo Data [Source](https://github.com/masakhane-io/lafand-mt/tree/main/data/text_files/en-ibo)\n",
    "\n",
    "This data has `10000` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba0d2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "igbo_mt = [\"test.en\", \"test.ibo\", \"train.en\", \"train.ibo\", \"dev.en\", \"dev.ibo\"]\n",
    "for data in igbo_mt:\n",
    "    !wget -P $temp_dir https://raw.githubusercontent.com/masakhane-io/lafand-mt/main/data/text_files/en-ibo/$data\n",
    "    display.clear_output()\n",
    "\n",
    "## merge all .ibo and .en files in igbo_mt list\n",
    "for lang in [\"en\", \"ibo\"]:\n",
    "    with open(temp_dir+f'masakhane_igbo_en.{lang}', 'w') as outfile: \n",
    "        for language_split in igbo_mt:\n",
    "            if language_split.endswith(lang):\n",
    "                with open(temp_dir+language_split) as infile:\n",
    "                    outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\")\n",
    "\n",
    "# load merged .ibo and .en data and convert to the salt data format\n",
    "igbo = file_to_list(temp_dir+\"masakhane_igbo_en.ibo\")\n",
    "en = file_to_list(temp_dir+\"masakhane_igbo_en.en\")\n",
    "\n",
    "sentences = []\n",
    "for s, t in zip(igbo, en):\n",
    "    sentences.append({'text': {'ibo': s, 'eng': t}})\n",
    "\n",
    "with open(OUTPUT_DIR + 'masakhane_igbo_en.jsonl', 'w', encoding='utf-8') as outfile:\n",
    "    for entry in sentences:\n",
    "        json.dump(entry, outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "# delete temporary directory\n",
    "!rm -rf $temp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0224b",
   "metadata": {},
   "source": [
    "### FaceBook No language left Behind (NLLB) Data [Source](https://huggingface.co/datasets/allenai/nllb/blob/main/README.md)\n",
    "\n",
    "It was recommended to use the data only for training purposes. This data has `6110033` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2e566b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nllb/eng_Latn-ibo_Latn (download: 930.30 MiB, generated: 2.58 GiB, post-processed: Unknown size, total: 3.48 GiB) to /Users/user/.cache/huggingface/datasets/allenai___nllb/eng_Latn-ibo_Latn/1.0.0/28d4a24ef4e17a539baee89254dc6a56e75b1a7a10b1055757f2512af99f5b30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 975M/975M [54:23<00:00, 299kB/s]    \n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nllb downloaded and prepared to /Users/user/.cache/huggingface/datasets/allenai___nllb/eng_Latn-ibo_Latn/1.0.0/28d4a24ef4e17a539baee89254dc6a56e75b1a7a10b1055757f2512af99f5b30. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# the data is quite large, so it takes up to an hour to download\n",
    "igbo_dataset = load_dataset(\"allenai/nllb\", \"eng_Latn-ibo_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79cda26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'laser_score', 'source_sentence_lid', 'target_sentence_lid', 'source_sentence_source', 'source_sentence_url', 'target_sentence_source', 'target_sentence_url'],\n",
       "        num_rows: 6110033\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "igbo_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b255ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "igbo_dataset_df = pd.DataFrame(igbo_dataset[\"train\"][\"translation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77c62938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_Latn</th>\n",
       "      <th>ibo_Latn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anas tells us that he replied, \"All those who ...</td>\n",
       "      <td>Anas na-agwa anyị na ọ zaghachiri, sị, \"Ndị ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"For in one hour such great wealth has been la...</td>\n",
       "      <td>n' ihi na n' otu awa ka a lara oké akụnụba dị ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They will come, and they will see my glory.</td>\n",
       "      <td>Ha ga-agakwuru, ha ga-hụ ebube m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In one hour this great wealth has been ruined.</td>\n",
       "      <td>n' ihi na n' otu awa ka a lara oké akụnụba dị ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seven days shall you wait until I come to you,...</td>\n",
       "      <td>Ị ga- echere m ruo ụbọchị asaa , ruo mgbe m ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            eng_Latn  \\\n",
       "0  Anas tells us that he replied, \"All those who ...   \n",
       "1  \"For in one hour such great wealth has been la...   \n",
       "2        They will come, and they will see my glory.   \n",
       "3     In one hour this great wealth has been ruined.   \n",
       "4  Seven days shall you wait until I come to you,...   \n",
       "\n",
       "                                            ibo_Latn  \n",
       "0  Anas na-agwa anyị na ọ zaghachiri, sị, \"Ndị ni...  \n",
       "1  n' ihi na n' otu awa ka a lara oké akụnụba dị ...  \n",
       "2                  Ha ga-agakwuru, ha ga-hụ ebube m.  \n",
       "3  n' ihi na n' otu awa ka a lara oké akụnụba dị ...  \n",
       "4  Ị ga- echere m ruo ụbọchị asaa , ruo mgbe m ga...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "igbo_dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68d9ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for row in igbo_dataset_df.itertuples():\n",
    "    sentences.append({'text': {'ibo': row.ibo_Latn, 'eng': row.eng_Latn}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c404b225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': {'ibo': 'Anas na-agwa anyị na ọ zaghachiri, sị, \"Ndị niile na-atụ egwu Allah.\"',\n",
       "  'eng': 'Anas tells us that he replied, \"All those who fear Allah.\"'}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "806e4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR + 'nllb_ibo_train.jsonl', 'w', encoding='UTF-8', errors='ignore') as outfile:\n",
    "    for entry in sentences:\n",
    "        json.dump(entry, outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d4094-fcad-425d-89d0-d2b4ce220285",
   "metadata": {},
   "source": [
    "# FLORES 200\n",
    "\n",
    "This dataset contains 2000 sentences with translations in 44 different African languages. We combine the dev and devtest splits into a single set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fd769c-0c38-4915-afa3-b513b488a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('flores200_dataset'):\n",
    "    !wget --trust-server-names https://tinyurl.com/flores200dataset\n",
    "    !tar xvzf flores200_dataset.tar.gz \n",
    "    display.clear_output()\n",
    "\n",
    "# languages = ['lug', 'eng', 'ibo', 'ewe', 'fon', 'hau', 'kam', 'kea', 'kik', 'kin',\n",
    "#              'kmb', 'kon', 'lin', 'lua', 'luo', 'nso', 'nya', 'gaz', 'run', 'sag',\n",
    "#              'sna', 'som', 'sot', 'ssw', 'swh', 'tir', 'tsn', 'tso', 'tum', 'twi',\n",
    "#              'umb', 'wol', 'xho', 'yor', 'zul', 'aka', 'amh', 'bam', 'bem', 'cjk',\n",
    "#              'dik', 'dyu', 'fuv', 'kbp']\n",
    "\n",
    "languages = ['lug', 'luo', 'ibo']\n",
    "source_sentences = {}\n",
    "\n",
    "for language in languages:\n",
    "    dev_path = glob.glob(f'flores200_dataset/dev/{language}*.dev')[0]\n",
    "    devtest_path = glob.glob(f'flores200_dataset/devtest/{language}*.devtest')[0]\n",
    "    source_sentences[language] = file_to_list(dev_path) + file_to_list(devtest_path)\n",
    "    if not len(source_sentences[language]):\n",
    "        raise ValueError(f'No text found for language {language}.')  \n",
    "\n",
    "N = len(source_sentences['lug'])\n",
    "sentences = []\n",
    "for i in range(N):\n",
    "    sentence = {'text': {}}\n",
    "    for language in languages:\n",
    "        sentence['text'][language] = source_sentences[language][i] \n",
    "    sentences.append(sentence)\n",
    "\n",
    "with open(OUTPUT_DIR + f'flores200.jsonl', 'w') as outfile:\n",
    "    for entry in sentences:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1759c",
   "metadata": {},
   "source": [
    "# Get number of words in test and dev SALT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff5a9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_eng_words(json_file_path):\n",
    "    salt_data = []\n",
    "    for line in open(json_file_path, 'r'):\n",
    "        salt_data.append(json.loads(line))\n",
    "\n",
    "    values = [salt_data_[\"text\"] for salt_data_ in salt_data]\n",
    "\n",
    "    salt_data = pd.DataFrame(values)\n",
    "\n",
    "    salt_data[\"no_of_enWords\"] = salt_data[\"eng\"].apply(lambda n: len(n.split()))\n",
    "\n",
    "    mean_number_of_english_words = salt_data[\"no_of_enWords\"].mean()\n",
    "    total_number_of_english_words = sum(salt_data[\"no_of_enWords\"])\n",
    "\n",
    "    print(\"mean_number_of_english_words: \", round(mean_number_of_english_words), \"\\n\",\n",
    "        \"total_number_of_english_words: \", total_number_of_english_words)\n",
    "\n",
    "    return total_number_of_english_words, salt_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1eb3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_number_of_english_words:  9 \n",
      " total_number_of_english_words:  4571\n",
      "mean_number_of_english_words:  9 \n",
      " total_number_of_english_words:  4469\n",
      "\n",
      " Total number of words in dev and test:  9040\n"
     ]
    }
   ],
   "source": [
    "salt_test = \"salt-translation-plus-external-datasets/salt-test.jsonl\"\n",
    "salt_dev = \"salt-translation-plus-external-datasets/salt-dev.jsonl\"\n",
    "\n",
    "no_of_test_eng_words, salt_test_df = get_number_of_eng_words(salt_test)\n",
    "no_of_dev_eng_words, salt_dev_df = get_number_of_eng_words(salt_dev)\n",
    "\n",
    "# total number of words in dev and test\n",
    "total_ = no_of_test_eng_words + no_of_dev_eng_words\n",
    "print(\"\\n\", \"Total number of words in dev and test: \", total_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d74e3fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>lug</th>\n",
       "      <th>ach</th>\n",
       "      <th>teo</th>\n",
       "      <th>lgg</th>\n",
       "      <th>nyn</th>\n",
       "      <th>no_of_enWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's the government's responsibility to teach ...</td>\n",
       "      <td>Buvunaanyizibwa bwa gavumenti okusomesa abantu...</td>\n",
       "      <td>Obedo tic pa gamente me pwonyo lwak i kom two ...</td>\n",
       "      <td>Erai aswam apugan aisisianakin itunga ke nuika...</td>\n",
       "      <td>Eri azi gamete ni imbata fezu 'ba ivile 'diyin...</td>\n",
       "      <td>N'obujunanizibwa bwa Gavumenti okwegyesa abant...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The issue of land grabbing is on a rise.</td>\n",
       "      <td>Ekibba ttaka kyeyongedde nnyo.</td>\n",
       "      <td>Time me mayo ngom tektek tye ka medde ameda.</td>\n",
       "      <td>Iyatasi noi akiro nuka aidem alupok.</td>\n",
       "      <td>E'yo angu opazaniri turia</td>\n",
       "      <td>Eshonga y'okwiba eitaka neyeyongyera.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parents educate their children.</td>\n",
       "      <td>Abazadde basomesa abaana baabwe.</td>\n",
       "      <td>Lunyodo pwonyo lutino gi</td>\n",
       "      <td>Itosiomete auriak idwe kec.</td>\n",
       "      <td>Tipika eyi onita fe anzi eyivile 'diyini</td>\n",
       "      <td>Abazaire nibegyesa abaana baabo.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I passed all the questions in the examination ...</td>\n",
       "      <td>Nnatuuka ebibuuzo byonna ebyali ku lupapula lw...</td>\n",
       "      <td>Akato lapeny weng ma obedo i karatac peny.</td>\n",
       "      <td>Abu eong atub aingiseta kere luka apapula kangin.</td>\n",
       "      <td>Ma aga ozita karitasi obeta ni ma alia dria ra</td>\n",
       "      <td>Nkahika ebibuuzo byona ebyabaire biri omu kigy...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Several musicians held a concert in honor of t...</td>\n",
       "      <td>Abayimbi abatali bamu baakoze ekivvulu okujjuk...</td>\n",
       "      <td>Lugo wer mapol guwero wer me po pi luremgi ma ...</td>\n",
       "      <td>Apotu ayook luipu kojaikinos keda aitodiaret k...</td>\n",
       "      <td>Ba karakarau ongo co'ba 'diyi 'ye avita inzita...</td>\n",
       "      <td>Abeshongozi bamwe bakozireho ekiterane mukwiju...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng  \\\n",
       "0  It's the government's responsibility to teach ...   \n",
       "1           The issue of land grabbing is on a rise.   \n",
       "2                    Parents educate their children.   \n",
       "3  I passed all the questions in the examination ...   \n",
       "4  Several musicians held a concert in honor of t...   \n",
       "\n",
       "                                                 lug  \\\n",
       "0  Buvunaanyizibwa bwa gavumenti okusomesa abantu...   \n",
       "1                     Ekibba ttaka kyeyongedde nnyo.   \n",
       "2                   Abazadde basomesa abaana baabwe.   \n",
       "3  Nnatuuka ebibuuzo byonna ebyali ku lupapula lw...   \n",
       "4  Abayimbi abatali bamu baakoze ekivvulu okujjuk...   \n",
       "\n",
       "                                                 ach  \\\n",
       "0  Obedo tic pa gamente me pwonyo lwak i kom two ...   \n",
       "1       Time me mayo ngom tektek tye ka medde ameda.   \n",
       "2                           Lunyodo pwonyo lutino gi   \n",
       "3         Akato lapeny weng ma obedo i karatac peny.   \n",
       "4  Lugo wer mapol guwero wer me po pi luremgi ma ...   \n",
       "\n",
       "                                                 teo  \\\n",
       "0  Erai aswam apugan aisisianakin itunga ke nuika...   \n",
       "1               Iyatasi noi akiro nuka aidem alupok.   \n",
       "2                        Itosiomete auriak idwe kec.   \n",
       "3  Abu eong atub aingiseta kere luka apapula kangin.   \n",
       "4  Apotu ayook luipu kojaikinos keda aitodiaret k...   \n",
       "\n",
       "                                                 lgg  \\\n",
       "0  Eri azi gamete ni imbata fezu 'ba ivile 'diyin...   \n",
       "1                          E'yo angu opazaniri turia   \n",
       "2           Tipika eyi onita fe anzi eyivile 'diyini   \n",
       "3     Ma aga ozita karitasi obeta ni ma alia dria ra   \n",
       "4  Ba karakarau ongo co'ba 'diyi 'ye avita inzita...   \n",
       "\n",
       "                                                 nyn  no_of_enWords  \n",
       "0  N'obujunanizibwa bwa Gavumenti okwegyesa abant...             11  \n",
       "1              Eshonga y'okwiba eitaka neyeyongyera.              9  \n",
       "2                   Abazaire nibegyesa abaana baabo.              4  \n",
       "3  Nkahika ebibuuzo byona ebyabaire biri omu kigy...              9  \n",
       "4  Abeshongozi bamwe bakozireho ekiterane mukwiju...             11  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21de2757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt_dev_df:  (500, 7)\n",
      "salt_test_df:  (500, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"salt_dev_df: \", salt_dev_df.shape)\n",
    "print(\"salt_test_df: \", salt_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d41a8-8cf0-439a-9596-a2472c1367bf",
   "metadata": {},
   "source": [
    "# Monolingual text (web scraped)\n",
    "\n",
    "Data was scraped from the web using [this code](https://github.com/SunbirdAI/parallel-text-EDA/tree/main/back_translation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3994c025-b265-4fea-af9c-f3dc85d49463",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prefix = ('https://raw.githubusercontent.com/SunbirdAI/'\n",
    "              'parallel-text-EDA/main/back_translation/data/')\n",
    "english_sentences = url_to_list(url_prefix + 'eng/daily-monitor.txt')\n",
    "english_sentences += url_to_list(url_prefix + 'eng/new-vision.txt')\n",
    "english_sentences = [{'text': {'eng': s}} for s in english_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d45445-ae71-4550-89b6-8c11c6502a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "luganda_sentences = url_to_list(url_prefix + 'lug/bukedde.txt')\n",
    "luganda_sentences += url_to_list(url_prefix + 'lug/makerere.txt')\n",
    "luganda_sentences = [{'text': {'lug': s}} for s in luganda_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa06fc69-2323-4b9a-82e1-703d0950443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acholi_sentences = url_to_list(url_prefix + 'ach/acholi-online.txt')\n",
    "acholi_sentences += url_to_list(url_prefix + 'ach/misc.txt')\n",
    "acholi_sentences += url_to_list(url_prefix + 'ach/rupiny.txt')\n",
    "acholi_sentences = [{'text': {'ach': s}} for s in acholi_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c59d96b2-971a-49f9-bb12-ec1b3b0743fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6655, 12304, 88613)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acholi_sentences), len(luganda_sentences), len(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "378b7fff-ab48-4af6-8dd6-71f8a48cb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR + f'monolingual-eng.jsonl', 'w') as outfile:\n",
    "    for entry in english_sentences:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "with open(OUTPUT_DIR + f'monolingual-lug.jsonl', 'w') as outfile:\n",
    "    for entry in luganda_sentences:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')\n",
    "        \n",
    "with open(OUTPUT_DIR + f'monolingual-ach.jsonl', 'w') as outfile:\n",
    "    for entry in acholi_sentences:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda340e-9d59-4a85-bf82-af4b93fa1e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ml-exp-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f1d252ef46601678906dbdce4acb4f440340dbfaa288531fe6c2b835d5664f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython import display\n!pip install transformers\n!pip install sacrebleu\n!pip install sacremoses\n!pip install datasets\n!pip install wandb\n!pip install sentencepiece\n!pip install nltk>=3.4.5\n!pip install numpy requests nlpaug\n!wget https://raw.githubusercontent.com/SunbirdAI/nmt_training/main/salt_v2/salt.py\n!wget https://raw.githubusercontent.com/SunbirdAI/nmt_training/main/nmt_clean/augmentations.py\ndisplay.clear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-28T15:39:44.988847Z","iopub.execute_input":"2023-03-28T15:39:44.990571Z","iopub.status.idle":"2023-03-28T15:41:20.832183Z","shell.execute_reply.started":"2023-03-28T15:39:44.990496Z","shell.execute_reply":"2023-03-28T15:41:20.830935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from augmentations import Augmentations\nimport datasets\nfrom IPython import display\nimport nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\nfrom nlpaug.util.file.download import DownloadUtil\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport sentencepiece\nimport sacrebleu\nimport sacremoses\nimport salt\nimport tqdm\nimport transformers\nimport torch\nimport wandb\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:41:20.835667Z","iopub.execute_input":"2023-03-28T15:41:20.836060Z","iopub.status.idle":"2023-03-28T15:41:20.844926Z","shell.execute_reply.started":"2023-03-28T15:41:20.836023Z","shell.execute_reply":"2023-03-28T15:41:20.843461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/temp","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:41:20.846763Z","iopub.execute_input":"2023-03-28T15:41:20.847092Z","iopub.status.idle":"2023-03-28T15:41:21.998995Z","shell.execute_reply.started":"2023-03-28T15:41:20.847061Z","shell.execute_reply":"2023-03-28T15:41:21.997319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DownloadUtil.download_word2vec(dest_dir='/kaggle/temp') # Download word2vec model\n#DownloadUtil.download_glove(model_name='glove.6B', dest_dir='/kaggle/temp') # Download GloVe model\nDownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='/kaggle/temp') # Download fasttext model\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:41:22.002535Z","iopub.execute_input":"2023-03-28T15:41:22.002961Z","iopub.status.idle":"2023-03-28T15:41:54.594460Z","shell.execute_reply.started":"2023-03-28T15:41:22.002920Z","shell.execute_reply":"2023-03-28T15:41:54.593094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#embeddings_augmentation = naw.WordEmbsAug(model_type='fasttext',\n#                      model_path=\"/kaggle/temp/wiki-news-300d-1M.vec\",top_k=10, aug_p=0.05, aug_min=0,aug_max=2)\nswap_augmentation = naw.random.RandomWordAug(\"swap\", aug_p=0.015, aug_min=0,aug_max=1)\ndelete_augmentation = naw.random.RandomWordAug(\"delete\", aug_p=0.015, aug_min=0,aug_max=1)\n\n# sometimes_augmenter = naf.sometimes.Sometimes([\n#     embeddings_augmentation, \n#     swap_augmentation,\n#     delete_augmentation\n    \n# ])\n\nmultiple_augs = Augmentations(\n[\n    #embeddings_augmentation,\n    swap_augmentation,\n    delete_augmentation\n]\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:57:18.303484Z","iopub.execute_input":"2023-03-28T15:57:18.304118Z","iopub.status.idle":"2023-03-28T15:57:18.313090Z","shell.execute_reply.started":"2023-03-28T15:57:18.304075Z","shell.execute_reply":"2023-03-28T15:57:18.311646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_text = multiple_augs([\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\",\n    \"Testing again is this shit too ducking slow fuck\"\n])","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:57:20.272607Z","iopub.execute_input":"2023-03-28T15:57:20.273027Z","iopub.status.idle":"2023-03-28T15:57:20.280792Z","shell.execute_reply.started":"2023-03-28T15:57:20.272992Z","shell.execute_reply":"2023-03-28T15:57:20.279436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_text","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:57:20.502907Z","iopub.execute_input":"2023-03-28T15:57:20.503340Z","iopub.status.idle":"2023-03-28T15:57:20.511671Z","shell.execute_reply.started":"2023-03-28T15:57:20.503297Z","shell.execute_reply":"2023-03-28T15:57:20.510243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aug_p (float) – Percentage of word will be augmented.\n# aug_min (int) – Minimum number of word will be augmented.\n# aug_max (int) – Maximum number of word will be augmented. If None is passed, number of augmentation is calculated via aup_p. If calculated result from aug_p is smaller than aug_max, will use calculated result from aug_p. Otherwise, using aug_max.","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:41:57.930000Z","iopub.execute_input":"2023-03-28T15:41:57.931625Z","iopub.status.idle":"2023-03-28T15:41:57.941917Z","shell.execute_reply.started":"2023-03-28T15:41:57.931548Z","shell.execute_reply":"2023-03-28T15:41:57.940677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:41:57.944029Z","iopub.execute_input":"2023-03-28T15:41:57.944941Z","iopub.status.idle":"2023-03-28T15:41:57.957298Z","shell.execute_reply.started":"2023-03-28T15:41:57.944893Z","shell.execute_reply":"2023-03-28T15:41:57.955075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters for mul-en models\nconfig = {\n    'source_language': 'eng',\n    'target_language': 'many',\n    'metric_for_best_model': 'loss',\n    'effective_train_batch_size': 5000,\n    'max_input_length': 128,\n    'validation_samples_per_language': 500,\n    'eval_languages': [\"ach\", \"lgg\", \"lug\", \"nyn\", \"teo\", \"luo\"],\n    'eval_pretrained_model': True,\n    'learning_rate': 5e-4,\n    'num_train_epochs': 10,\n    'label_smoothing_factor': 0.1,\n    'mt560_relative_sample_rate' : 0.2,\n    'flores200_training_data': True,\n    'mt560_training_data': True,\n    'monolingual_training_data': False,\n    'back_translation_training_data': True,\n    'google_back_translation_data': True,\n    'named_entities_training_data': False,\n    'lafand_training_data': True,\n    'tag_subsets': True,\n    'aug_subsets': True,\n    'early_stopping_patience': 4,\n    'eval_steps_interval': 50,\n    'data_dir': 'salt-translation-plus-external-datasets-15-3-23',\n}\n\nconfig['language_pair'] = (f'{config[\"source_language\"]}-'\n                           f'{config[\"target_language\"]}')\nconfig['wandb_project'] = f'sunbird-translate-{config[\"language_pair\"]}'\nconfig['model_checkpoint'] = f'Helsinki-NLP/opus-mt-en-mul'\n#config['model_checkpoint'] = f'/kaggle/input/nmt-marianmt-w-mafand/best/checkpoint-600'\n#config['model_checkpoint'] = (\n#    '/content/gdrive/MyDrive/Translation/saved_models/'\n#    'marianmt-many-eng/checkpoint-1400')\n\n\n# Find the biggest batch size that fits in GPU memory\nAPPROX_MODEL_MEMORY_SIZE_MB = 310\nif torch.cuda.is_available():\n  gpu_info = !nvidia-smi\n  gpu_memory_mb = int(gpu_info[9].split()[10][:-3])\n  per_device_max_batch_size = int(gpu_memory_mb / APPROX_MODEL_MEMORY_SIZE_MB)\n  B = config['effective_train_batch_size'] \n  factors = np.array([x for x in range(1, B) if B % x == 0])\n  config['train_batch_size'] = int(max(\n      factors[factors < per_device_max_batch_size]))\n  config['eval_batch_size'] = config['train_batch_size']\nelse:\n  config['train_batch_size'] = 1\n  config['eval_batch_size'] = 1\nconfig['gradient_accumulation_steps'] = int(\n    config['effective_train_batch_size'] / config['train_batch_size'])\n\n# Trainer settings\nconfig['train_settings'] = transformers.Seq2SeqTrainingArguments(\n    output_dir= f'/kaggle/working/best',\n    evaluation_strategy = 'steps',\n    eval_steps = config['eval_steps_interval'],\n    save_steps = config['eval_steps_interval'],\n    gradient_accumulation_steps = config['gradient_accumulation_steps'],\n    learning_rate = config['learning_rate'],\n    per_device_train_batch_size = config['train_batch_size'],\n    per_device_eval_batch_size = config['eval_batch_size'],\n    weight_decay = 0.01,\n    save_total_limit = 3,\n    num_train_epochs = config['num_train_epochs'],\n    predict_with_generate = True,\n    fp16 = torch.cuda.is_available(),\n    logging_dir = f'/kaggle/working/best',\n    report_to = 'wandb',\n    run_name = f'{config[\"source_language\"]}-{config[\"target_language\"]}',\n    load_best_model_at_end=True,\n    metric_for_best_model = config['metric_for_best_model'],\n    label_smoothing_factor = config['label_smoothing_factor']\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:49:04.045380Z","iopub.execute_input":"2023-03-28T15:49:04.046168Z","iopub.status.idle":"2023-03-28T15:49:04.068167Z","shell.execute_reply.started":"2023-03-28T15:49:04.046123Z","shell.execute_reply":"2023-03-28T15:49:04.066894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config['training_subset_ids'] = ['salt-train', 'ai4d']\n\nif config['lafand_training_data']:\n    config['training_subset_ids'].extend(['lafand-en-lug-combined', 'lafand-en-luo-combined'])\n\nif config['flores200_training_data']:\n    config['training_subset_ids'] .append('flores200')\n\nif config['back_translation_training_data']:\n    config['training_subset_ids'].extend( ['bt_ach_en_14_3_23', 'bt_lug_en_14_3_23'])\n\nif config['back_translation_training_data']:\n    config['training_subset_ids'].extend(['backtranslated-from-eng-google', 'backtranslated-from-lug-google' ])\n\nconfig['training_subset_ids'] = config['training_subset_ids']*3\n\nif config['mt560_training_data']:\n    config['training_subset_ids'].extend([\n        'mt560_ach', 'mt560_lug', 'mt560_nyn','mt560_luo'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:49:05.096438Z","iopub.execute_input":"2023-03-28T15:49:05.096883Z","iopub.status.idle":"2023-03-28T15:49:05.105355Z","shell.execute_reply.started":"2023-03-28T15:49:05.096840Z","shell.execute_reply":"2023-03-28T15:49:05.103966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config[\"tag_subsets\"]:\n    config['training_subset_tags'] = [\"hq\", \"hq\"]\n\n    if config['lafand_training_data']:\n        config['training_subset_tags'].extend([ \"hq\",\"hq\" ])\n\n    if config['flores200_training_data']:\n        config['training_subset_tags'] .append(\"hq\") #hq?\n\n    if config['back_translation_training_data']:\n        config['training_subset_tags'].extend( [ \"bt\", \"bt\" ])\n\n    if config['back_translation_training_data']:\n        config['training_subset_tags'].extend([ \"ggl\", \"ggl\" ])\n\n    config['training_subset_tags'] = config['training_subset_tags']*3\n\n    if config['mt560_training_data']:\n        config['training_subset_tags'].extend([\n            \"ood\", \"ood\", \"ood\", \"ood\" ])\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:49:05.448674Z","iopub.execute_input":"2023-03-28T15:49:05.449108Z","iopub.status.idle":"2023-03-28T15:49:05.457066Z","shell.execute_reply.started":"2023-03-28T15:49:05.449068Z","shell.execute_reply":"2023-03-28T15:49:05.455853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config[\"aug_subsets\"]:\n    config['training_subset_augs'] = [True, True]\n\n    if config['lafand_training_data']:\n        config['training_subset_augs'].extend([ True,True ])\n\n    if config['flores200_training_data']:\n        config['training_subset_augs'] .append(True) #hq?\n\n    if config['back_translation_training_data']:\n        config['training_subset_augs'].extend( [ True, True ])\n\n    if config['back_translation_training_data']:\n        config['training_subset_augs'].extend([ True, True ])\n\n    config['training_subset_augs'] = config['training_subset_augs']*3\n\n    if config['mt560_training_data']:\n        config['training_subset_augs'].extend([\n            False, False, False, False ])","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:49:05.723564Z","iopub.execute_input":"2023-03-28T15:49:05.724662Z","iopub.status.idle":"2023-03-28T15:49:05.732476Z","shell.execute_reply.started":"2023-03-28T15:49:05.724608Z","shell.execute_reply":"2023-03-28T15:49:05.731433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(config[\"training_subset_tags\"]) == len(config[\"training_subset_ids\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:49:09.773267Z","iopub.execute_input":"2023-03-28T15:49:09.773678Z","iopub.status.idle":"2023-03-28T15:49:09.779816Z","shell.execute_reply.started":"2023-03-28T15:49:09.773641Z","shell.execute_reply":"2023-03-28T15:49:09.778293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('salt-translation-plus-external-datasets-15-3-23'):\n    !wget https://sunbird-translate.s3.us-east-2.amazonaws.com/salt-translation-plus-external-datasets-15-3-23.zip\n    !unzip salt-translation-plus-external-datasets-15-3-23.zip\n    display.clear_output()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:49:09.993481Z","iopub.execute_input":"2023-03-28T15:49:09.994678Z","iopub.status.idle":"2023-03-28T15:49:15.688855Z","shell.execute_reply.started":"2023-03-28T15:49:09.994626Z","shell.execute_reply":"2023-03-28T15:49:15.687187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n# training_subsets = [\n#     salt.translation_dataset(\n#         path=f'{config[\"data_dir\"]}/{id}.jsonl',\n#         source_language=config['source_language'],\n#         target_language=config['target_language'],\n#         allow_target_language_in_source=False,\n#         prefix_target_language_in_source=True,\n#         dataset_prefixes = dataset_tags,\n#         languages_to_include=config['eval_languages'],\n#         keep_unaugmented_src = False)\n#     for id, dataset_tags in tqdm(zip(config['training_subset_ids'],config['training_subset_tags'] ) )\n# ]\n\ntraining_subsets = []\n\nfor id,aug_flag, dataset_tags in tqdm(zip(config['training_subset_ids'],config['training_subset_augs'],config['training_subset_tags'] )):\n    for language in config[\"eval_languages\"]:\n        training_subset = salt.translation_dataset(\n            path=f'{config[\"data_dir\"]}/{id}.jsonl',\n            source_language=config['source_language'],\n            target_language=language,\n            allow_target_language_in_source=False,\n            prefix_target_language_in_source=False,\n            dataset_prefixes = [f\">>{language}_{dataset_tags}<<\"],\n            languages_to_include=language,\n            keep_unaugmented_src = False)\n        training_subsets.append(training_subset)\n        if aug_flag:\n            training_subset = salt.translation_dataset(\n            path=f'{config[\"data_dir\"]}/{id}.jsonl',\n            source_language=config['source_language'],\n            target_language=language,\n            allow_target_language_in_source=False,\n            prefix_target_language_in_source=False,\n            source_augmenter = multiple_augs,\n            dataset_prefixes = [f\">>{language}_aug_{dataset_tags}<<\"],\n            languages_to_include=language,\n            keep_unaugmented_src = False)\n            training_subsets.append(training_subset)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T15:57:27.284939Z","iopub.execute_input":"2023-03-28T15:57:27.285380Z","iopub.status.idle":"2023-03-28T16:02:36.702327Z","shell.execute_reply.started":"2023-03-28T15:57:27.285327Z","shell.execute_reply":"2023-03-28T16:02:36.700753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_probabilities = np.array([len(s) for s in training_subsets])\n# sample_probabilities = sample_probabilities * np.array(\n#     [config['mt560_relative_sample_rate'] if ('mt560' in id) or ('google' in id)  else 1.0\n#      for id in config['training_subset_ids']])\n# sample_probabilities = sample_probabilities / np.sum(sample_probabilities)\n\n# train_data_raw = datasets.interleave_datasets(\n#     training_subsets, sample_probabilities)\ntrain_data_raw = datasets.concatenate_datasets(training_subsets)\ntrain_data_raw = train_data_raw.shuffle()\ntrain_data_raw = train_data_raw.flatten_indices()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:12:40.285257Z","iopub.execute_input":"2023-03-28T16:12:40.285760Z","iopub.status.idle":"2023-03-28T16:13:24.868646Z","shell.execute_reply.started":"2023-03-28T16:12:40.285722Z","shell.execute_reply":"2023-03-28T16:13:24.867414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_subsets = [\n    salt.translation_dataset(\n        path=f'{config[\"data_dir\"]}/salt-dev.jsonl',\n        source_language=\"eng\",\n        target_language=language,\n        keep_unaugmented_src = False,\n        allow_target_language_in_source=False,\n        prefix_target_language_in_source=False,\n        dataset_prefixes = [f\">>{language}_hq<<\"]\n    )\n    for language in config['eval_languages'][:-1]\n]\nvalidation_data_raw = datasets.concatenate_datasets(validation_subsets)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:14:36.306775Z","iopub.execute_input":"2023-03-28T16:14:36.307202Z","iopub.status.idle":"2023-03-28T16:14:36.360851Z","shell.execute_reply.started":"2023-03-28T16:14:36.307158Z","shell.execute_reply":"2023-03-28T16:14:36.359459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentence_format(input):\n    '''Ensure capital letter at the start and full stop at the end.'''\n    try:\n        input = input[0].capitalize() + input[1:]\n        if input[-1] not in ['.', '!', '?']:\n            input = input + '.'\n    except:\n        return \"\"\n    return input\n\ndef preprocess(examples):\n    normalizer = sacremoses.MosesPunctNormalizer()  \n    inputs = []\n    targets = []\n    for input, target in zip(examples['source'], examples['target']):\n        if not len(input):\n          input = target\n        inputs.append(sentence_format(normalizer.normalize(input)))\n        targets.append(sentence_format(normalizer.normalize(target)))\n    \n    model_inputs = tokenizer(\n        inputs, text_target=targets,\n        max_length=config['max_input_length'], truncation=True)\n\n    return model_inputs\n\ndef postprocess(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds, eval_languages, samples_per_language):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n        \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess(decoded_preds, decoded_labels)\n    result = {}\n    for i, lang in enumerate(eval_languages):\n        \n        result_subset = metric.compute(\n            predictions=decoded_preds[\n                i*samples_per_language:(i+1)*samples_per_language],\n            references=decoded_labels[\n                i*samples_per_language:(i+1)*samples_per_language])\n        result[f\"BLEU_{lang}\"] = result_subset[\"score\"]\n        \n    result[\"BLEU_mean\"] = np.mean(\n        [result[f\"BLEU_{lang}\"] for lang in eval_languages])\n    \n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:14:43.491074Z","iopub.execute_input":"2023-03-28T16:14:43.491557Z","iopub.status.idle":"2023-03-28T16:14:43.509126Z","shell.execute_reply.started":"2023-03-28T16:14:43.491514Z","shell.execute_reply":"2023-03-28T16:14:43.507735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = transformers.AutoModelForSeq2SeqLM.from_pretrained(config['model_checkpoint'])\ntokenizer = transformers.AutoTokenizer.from_pretrained(config['model_checkpoint'])\ndata_collator = transformers.DataCollatorForSeq2Seq(tokenizer, model = model) \nmetric = datasets.load_metric('sacrebleu')","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:14:43.698696Z","iopub.execute_input":"2023-03-28T16:14:43.699192Z","iopub.status.idle":"2023-03-28T16:14:53.678353Z","shell.execute_reply.started":"2023-03-28T16:14:43.699137Z","shell.execute_reply":"2023-03-28T16:14:53.676925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config['target_language'] == 'many':\n    replacements = {'nyn_ood': 'ewe',\n                    'nyn_ggl': 'sna',\n                    'nyn_hq': 'lin',\n                    'nyn_bt': 'toi_Latn',\n                    #'nyn_aug_ood': 'ceb',\n                    'nyn_aug_ggl': 'oss',\n                    'nyn_aug_hq':'run' ,\n                    'nyn_aug_bt': 'mfe',\n                    'teo_ood': 'ilo',\n                    'teo_ggl': 'zlm_Latn',\n                    'teo_hq': 'pes', \n                    'teo_bt': 'smo',\n                    #'teo_aug_ood': 'hil',\n                    'teo_aug_ggl': 'niu',\n                    'teo_aug_hq': 'sag', \n                    'teo_aug_bt': 'fij',\n                    'lgg_ood': 'cmn_Hans',\n                    'lgg_ggl': 'nya',\n                    'lgg_bt': 'tso',\n                    'lgg_hq': 'war',\n                    #'lgg_aug_ood': 'gil',\n                    'lgg_aug_ggl': 'hau_Latn',\n                    'lgg_aug_bt': 'umb',\n                    'lgg_aug_hq': 'glv',\n                    'ach_ood': 'tvl',\n                    'ach_ggl': 'ton',\n                    'ach_hq': 'zul',\n                    'ach_bt': 'kal',\n                    #'ach_aug_ood': 'pag',\n                    'ach_aug_ggl': 'bak',#'cmn_Hant',\n                    'ach_aug_hq': 'pus',\n                    'ach_aug_bt': 'abk',\n                    'lug_ood': 'pap',\n                    'lug_ggl': 'hat',\n                    'lug_hq': 'lug',#'mkd',\n                    'lug_bt': 'tuk_Latn',\n                    #'lug_aug_ood': 'yor',\n                    'lug_aug_ggl': 'tuk',\n                    'lug_aug_hq': 'sqi',\n                    'lug_aug_bt': 'tir',                    \n                    'luo_ood': 'mlg',\n                    'luo_ggl': 'tur',\n                    'luo_hq': 'ido_Latn',\n                    'luo_bt': 'mai',\n                    #'luo_aug_ood': 'ibo',\n                    'luo_aug_ggl': 'heb',#'srp_Cyrl',\n                    'luo_aug_hq': 'srp_Latn',\n                    'luo_aug_bt': 'bos_Latn'#'kir_Cyrl',\n                    \n                    }\n#['>>ewe<<','>>sna<<','>>lin<<','>>toi_Latn<<','>>ceb<<','>>oss<<','>>run<<','>>mfe<<','>>ilo<<','>>zlm_Latn<<','>>pes<<',\n#'>>smo<<','>>hil<<','>>niu<<','>>sag<<','>>fij<<','>>cmn_Hans<<','>>nya<<','>>tso<<','>>war<<',\n#'>>gil<<','>>hau_Latn<<','>>umb<<','>>glv<<','>>tvl<<','>>ton<<','>>zul<<','>>kal<<','>>pag<<','>>cmn_Hant<<',\n#'>>pus<<','>>abk<<','>>pap<<','>>hat<<','>>mkd<<','>>tuk_Latn<<','>>yor<<','>>tuk<<','>>sqi<<','>>tir<<','>>mlg<<',\n#'>>tur<<','>>ido_Latn<<','>>mai<<','>>ibo<<','>>srp_Cyrl<<','>>srp_Latn<<','>>kir_Cyrl<<','>>heb<<','>>bos_Latn<<',\n#'>>bak<<','>>ast<<','>>som<<','>>tah<<','>>chv<<','>>kek_Latn<<','>>lug<<','>>vie<<',\n#'>>wln<<','>>isl<<','>>hye<<','>>mah<<','>>yue_Hant<<','>>crh_Latn<<','>>amh<<','>>nds<<','>>pan_Guru<<','>>xho<<','>>ukr<<',\n#'>>cat<<','>>afr<<','>>tat<<','>>guj<<','>>jpn<<','>>mon<<','>>eus<<','>>nob<<','>>glg<<','>>ind<<','>>sin<<','>>cym<<','>>zho_Hant<<',\n#'>>zho_Hans<<','>>tgk_Cyrl<<','>>aze_Latn<<','>>ltz<<','>>bod<<','>>asm<<','>>tel<<','>>urd<<','>>kaz_Cyrl<<','>>lat_Latn<<','>>gla<<',\n#'>>kan<<','>>bul<<','>>kin<<','>>ina_Latn<<','>>ron<<','>>spa<<','>>csb_Latn<<','>>iba<<','>>tha<<','>>nno<<','>>hrv<<','>>fry<<','>>bre<<',\n#'>>mar<<','>>sme<<','>>swe<<','>>deu<<','>>jav<<','>>snd_Arab<<','>>ben<<','>>cmn<<','>>ces<<''>>ita<<','>>fin<<','>>por<<','>>hin<<',\n#'>>hun<<','>>mal<<','>>pol<<','>>fra<<','>>nld<<','>>epo<<','>>slv<<','>>hsb<<','>>kur_Latn<<','>>ori<<','>>tam<<','>>bel<<','>>dan<<',\n#'>>ara<<','>>mya<<','>>rus<<','>>mri<<','>>est<<','>>uzb_Latn<<','>>lao<<','>>yid<<','>>uzb_Cyrl<<','>>uig_Arab<<','>>lit<<','>>zho<<',\n#'>>lav<<','>>ell<<','>>kat<<''>>gle<<','>>mlt<<','>>khm<<','>>oci<<','>>kur_Arab<<','>>ang_Latn<<','>>kaz_Latn<<','>>wol<<','>>sun<<',\n#'>>chr<<','>>tat_Latn<<','>>mhr<<','>>tyv<<','>>rom<<','>>cha<<','>>kab<<','>>nav<<','>>arg<<','>>khm_Latn<<','>>bul_Latn<<','>>udm<<',\n#'>>quc<<','>>cor<<','>>san_Deva<<','>>fao<<','>>bel_Latn<<','>>jbo_Latn<<','>>yue<<','>>grn<<','>>sco<<','>>arq<<','>>ltg<<','>>yue_Hans<<',\n#'>>min<<''>>nan<<','>>bam_Latn<<','>>ido<<','>>ile_Latn<<','>>wuu<<','>>crh<<','>>tlh_Latn<<','>>lzh<<','>>jbo<<','>>lzh_Hans<<',\n#'>>vol_Latn<<','>>lfn_Latn<<','>>arz<<']\n    for r in replacements:\n        if (f'>>{r}<<' not in tokenizer.encoder and\n            f'>>{replacements[r]}<<' in tokenizer.encoder):\n            tokenizer.encoder[f\">>{r}<<\"] = tokenizer.encoder[f\">>{replacements[r]}<<\"]\n            del tokenizer.encoder[f\">>{replacements[r]}<<\"]\n\n    # Check that all the evaluation language codes are mapped to something.\n#     for r in config['eval_languages']:\n#         if f'>>{r}<<' not in tokenizer.encoder:\n#             raise ValueError(f'Language code {r} not found in the encoder.')","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:14:53.681164Z","iopub.execute_input":"2023-03-28T16:14:53.681604Z","iopub.status.idle":"2023-03-28T16:14:53.698072Z","shell.execute_reply.started":"2023-03-28T16:14:53.681562Z","shell.execute_reply":"2023-03-28T16:14:53.696733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data  = train_data_raw.map(\n    preprocess,\n    remove_columns=['source', 'target', 'source_language', 'target_language'],\n    batched=True)\n\nvalidation_data  = validation_data_raw.map(\n    preprocess,\n    remove_columns=['source', 'target', 'source_language', 'target_language'],\n    batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:15:08.281972Z","iopub.execute_input":"2023-03-28T16:15:08.282447Z","iopub.status.idle":"2023-03-28T16:15:14.579788Z","shell.execute_reply.started":"2023-03-28T16:15:08.282405Z","shell.execute_reply":"2023-03-28T16:15:14.577849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\nimport os\nos.environ[\"WANDB_API_KEY\"] = secret_value_0\nwandb.init(project=config['wandb_project'], config=config, entity=\"azawahry\")\n\ntransformers.logging.set_verbosity_error()\n\ntrainer = transformers.Seq2SeqTrainer(\n    model,\n    config['train_settings'],\n    train_dataset = train_data,\n    eval_dataset = validation_data,\n    data_collator = data_collator,\n    tokenizer = tokenizer,\n    compute_metrics = lambda x: compute_metrics(\n        x, config['eval_languages'][:-1], config['validation_samples_per_language']),\n    callbacks = [\n        transformers.EarlyStoppingCallback(\n            early_stopping_patience = config['early_stopping_patience'])],\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T11:52:01.033779Z","iopub.execute_input":"2023-03-17T11:52:01.034275Z","iopub.status.idle":"2023-03-17T11:52:38.190474Z","shell.execute_reply.started":"2023-03-17T11:52:01.034227Z","shell.execute_reply":"2023-03-17T11:52:38.189453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if config['eval_pretrained_model']:\n#     trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T11:52:38.195292Z","iopub.execute_input":"2023-03-17T11:52:38.197742Z","iopub.status.idle":"2023-03-17T11:52:38.204177Z","shell.execute_reply.started":"2023-03-17T11:52:38.197700Z","shell.execute_reply":"2023-03-17T11:52:38.203008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T11:52:38.209112Z","iopub.execute_input":"2023-03-17T11:52:38.210546Z","iopub.status.idle":"2023-03-17T15:36:51.814471Z","shell.execute_reply.started":"2023-03-17T11:52:38.210508Z","shell.execute_reply":"2023-03-17T15:36:51.813396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
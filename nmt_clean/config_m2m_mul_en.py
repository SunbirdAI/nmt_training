
## FIXME this should be dynamically generated by src and tgt languages list
## TODO add a ratio variable that controls how much each subset is represented
config = {
    'flores101_training_data': True,
    'mt560_training_data': True,
    'back_translation_training_data': True,
    'front_translation_training_data': False, #not implemented
    'named_entities_training_data': False,
    'recycle_language_tokens': True,
    'google_back_translation': True,
    'oversample_rate': 5,
    'oversample_in_domain': True
}
config['data_dir'] = f'/home/ali/Documents/repos/datasets/salt/v7-dataset/'

config['training_subset_paths'] = {
            "ach":{
                "all":[config['data_dir'] + "v7.0/supervised/en-ach/train.ach"],
                "en":[],
                "lgg":[],
                "lug":[],
                "nyn":[],
                "teo":[]
            },
            "en": {
                "all":[config['data_dir'] + "v7.0/supervised/en-lug/train.en"],
                "ach":[],
                "lgg":[],
                "lug":[],
                "nyn":[],
                "teo":[]
            },
            "lgg":{
                "all":[config['data_dir'] + "v7.0/supervised/en-lgg/train.lgg"],
                "en":[],
                "ach":[],
                "lug":[],
                "nyn":[],
                "teo":[]
            },
            "lug":{
                "all":[config['data_dir'] + "v7.0/supervised/en-lug/train.lug"],
                "en":[],
                "lgg":[],
                "ach":[],
                "nyn":[],
                "teo":[]
            },
            "nyn":{
                "all":[config['data_dir'] + "v7.0/supervised/en-nyn/train.nyn"],
                "en":[],
                "lgg":[],
                "lug":[],
                "ach":[],
                "teo":[]
            },
            "teo":{
                "all":[config['data_dir'] + "v7.0/supervised/en-teo/train.teo"],
                "en":[],
                "lgg":[],
                "lug":[],
                "nyn":[],
                "ach":[]
            }
}
    
## All pairwise
config['validation_subset_paths'] = {
            "ach":{
                "all":[config['data_dir'] + "v7.0/supervised/en-ach/val.ach"],
                "en":[],
                "lgg":[],
                "lug":[],
                "nyn":[],
                "teo":[]
            },
            "en": {
                "all":[config['data_dir'] + "v7.0/supervised/en-lug/val.en"],
                "ach":[],
                "lgg":[],
                "lug":[],
                "nyn":[],
                "teo":[]
            },
            "lgg":{
                "all":[config['data_dir'] + "v7.0/supervised/en-lgg/val.lgg"],
                "en":[],
                "ach":[],
                "lug":[],
                "nyn":[],
                "teo":[]
            },
            "lug":{
                "all":[config['data_dir'] + "v7.0/supervised/en-lug/val.lug"],
                "en":[],
                "lgg":[],
                "ach":[],
                "nyn":[],
                "teo":[]
            },
            "nyn":{
                "all":[config['data_dir'] + "v7.0/supervised/en-nyn/val.nyn"],
                "en":[],
                "lgg":[],
                "lug":[],
                "ach":[],
                "teo":[]
            },
            "teo":{
                "all":[config['data_dir'] + "v7.0/supervised/en-teo/val.teo"],
                "en":[],
                "lgg":[],
                "lug":[],
                "nyn":[],
                "ach":[]
            }
}





config['testing_subset_paths'] = [
        
        {
            "source":{"language":"ach",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_ach.src"},
            "target":{"language":"en",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_ach.tgt"} 
        },
        {
            "source":{"language":"lgg",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_lgg.src"},
            "target":{"language":"en",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_lgg.tgt"} 
        },
        {
            "source":{"language":"lug",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_lug.src"},
            "target":{"language":"en",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_lug.tgt"} 
        },
        {
            "source":{"language":"nyn",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_nyn.src"},
            "target":{"language":"en",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_nyn.tgt"} 
        },
        {
            "source":{"language":"teo",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_teo.src"},
            "target":{"language":"en",
                   "path":config['data_dir'] + "v7.0/supervised/mul-en/test_teo.tgt"} 
        }
    
   ]


#why not luo?
if config['flores101_training_data']:
    
    config['training_subset_paths']["lug"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_flores_lug.src")
    config['training_subset_paths']["en"]["lug"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_flores_lug.tgt")
    
#Get them by matching indicies
# fragile but works
# I guess we need some tests

if config["back_translation_training_data"]:

        config['training_subset_paths']["ach"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/back_translate_ach.src")
        config['training_subset_paths']["en"]["ach"].append(config['data_dir'] + "v7.0/supervised/mul-en/back_translate_ach.tgt")
        config['training_subset_paths']["lug"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/back_translate_lug.src")
        config['training_subset_paths']["en"]["lug"].append(config['data_dir'] + "v7.0/supervised/mul-en/back_translate_lug.tgt")
        config['training_subset_paths']["teo"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/back_translate_teo.src")
        config['training_subset_paths']["en"]["teo"].append(config['data_dir'] + "v7.0/supervised/mul-en/back_translate_teo.tgt")


if config["google_back_translation"]:

        config['training_subset_paths']["lug"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/bukedde_ggl_bt_lug.src")
        config['training_subset_paths']["en"]["lug"].append(config['data_dir'] + "v7.0/supervised/mul-en/bukedde_ggl_bt_lug.tgt")

#TODO adjust        
if config["oversample_in_domain"]:
    for src_lang in config['training_subset_paths'].keys():
        for tgt_lang in config['training_subset_paths'][src_lang].keys():
            config['training_subset_paths'][src_lang][tgt_lang] = config['training_subset_paths'][src_lang][tgt_lang] * config["oversample_rate"]
    #redo oversampling

if config['mt560_training_data']:
            config['training_subset_paths']["ach"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_mt560_ach.src")
            config['training_subset_paths']["en"]["ach"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_mt560_ach.tgt")

            config['training_subset_paths']["lug"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_mt560_lug.src")
            config['training_subset_paths']["en"]["lug"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_mt560_lug.tgt")

            config['training_subset_paths']["nyn"]["en"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_mt560_nyn.src")
            config['training_subset_paths']["en"]["nyn"].append(config['data_dir'] + "v7.0/supervised/mul-en/train_mt560_nyn.tgt")
            

# if config['named_entities_training_data']:
#     rasie NotImplementedError("NER pairs are aggregate not separate")
#     config['training_subset_ids'].append('named_entities')

if config["recycle_language_tokens"]:
    config["token_conversion_dict"] = {
        "teo": 'ar_AR' ,
        "ach": 'cs_CZ',
        "lug": 'de_DE',
        "lgg": 'es_XX',
        "nyn": 'et_EE',
        "en": 'en_XX'
        
     }
#FIXME ugly and redundant remove need for it from preprocessor
else:
    config["token_conversion_dict"] = {
        "teo": 'teo' ,
        "ach": 'ach',
        "lug": 'lug',
        "lgg": 'lgg',
        "nyn": 'nyn',
        "en": 'en'
        
     }
    #raise NotImplementedError("Code to add tokens and resize embedding layer not added")
